{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your own classifyer using transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last module, using pre-trained models, we discussed the transfer-learning techniques, which is an extremely powerful and useful technique to get your own classifyer. The aim of this project is to do this in reality. In the file transfer learning tutorial you can find how to do this on a set of images containing either bees or ants. Let's see how to set up some transfer learning process for yourself.\n",
    "\n",
    "### Get data\n",
    "Collect image data which you would like to classify. You can either do this by downloading some  data from the internet or you can make images yourself. If you want to collect data yourself be careful that:\n",
    "1. the images are actually not to large. Most pretrained models have input size images of size (299,299,3) or (244,244,3). So this is really not very large. The model resizes the images and crops and turn the around. This is called data augementation. In the tutorial tranfer_learning_tutorial they use image of size around (500,500,3). As the images are resized before deployment it is not important that all images have exactly the same size.\n",
    "2. The images are made in a standarized way. For instance you make the images of one class let's say apples all with your phone while for the other class let's say pears you use the webcam of your computer then the network will probably learn to recognize to classify images of webcam and phone instead of apples an pear. If you then ask to classify an image of a pear made with your phone you run the risk it will consistently return apple. This is really tricky as performance measures as confusion matrix and accuracy will be really high then.\n",
    "3. that you get enough data. Even if you use a pretrained model it is import to train on a substantial set of images. Try to collect at least 200 images for each class.\n",
    "\n",
    "\n",
    "### Get the data in the directory structure\n",
    "\n",
    " If you want to do this yourself then do the following:\n",
    "1. make an directory called 'data',\n",
    "2. make a in this directory two subdirectories called 'train' and 'val',\n",
    "3. in both of these directories you make for each class a subdirectory  containing example images of that class. \n",
    "\n",
    "It is not important how many classes you use. In the example they have two classes but you could put as many as you want. Of course a classifyer that only distinguishes 1 class does not really work.\n",
    "\n",
    "It is good practice to split your images in each class for 60% in the training set and 40% in the validation set. If you really want to employ your classifyer you need actually to split in 60% training 20%test and 20% validation. Then you can use your validation sets to make decisions about your model and in the test set you can see the performance. Then, you might want to read more about this topic.  \n",
    "\n",
    "### modify one line in the script\n",
    "In the tranfer_learning_tutorial in the loading the data cell change\n",
    "\n",
    "data_dir = 'data/hymenoptera_data' \n",
    "\n",
    "to \n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "### execute and see what you have done.\n",
    "Execute all cells in the tutorial. You now have a model that can classify between your classes. Do some research how well it performs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
